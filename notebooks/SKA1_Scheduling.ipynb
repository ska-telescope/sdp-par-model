{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SDP Schedule Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../src\")\n",
    "\n",
    "from sdp_par_model.scheduling.simulation import ScheduleSimulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create app object that contains methods for simulating the SDP schedule\n",
    "\n",
    "There are no arguments when initialising the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = ScheduleSimulation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall observatory selection & capacities\n",
    "\n",
    "A scenario needs to be chosen to set the telescope, total number of FLOPS, and buffer sizes. The scenario must be one of: 'low-cdr', 'mid-cdr', 'low-adjusted', 'mid-adjusted'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario = \"mid-cdr\"\n",
    "\n",
    "app.observatory_sizes_and_rates(scenario)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read HPSO performance characteristics\n",
    "\n",
    "Loads high performance science objective (HPSO) characteristics generated by the export notebook. This picks up the latest file checked into Git by default, but a csv file path can be specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv generated from custom observations (first run Export.ipynb to generate the csv files)\n",
    "##########################################\n",
    "# app.read_hpso_csv(csv_file='../data/csv/custom_pipelines.csv') # should fail because no ingest pipeline\n",
    "app.read_hpso_csv(csv_file='../data/csv/custom_hpsos.csv') # should pass\n",
    "# app.read_hpso_csv(csv_file='../data/csv/custom_max_mid_band1.csv') # should pass\n",
    "# app.read_hpso_csv(csv_file='../data/csv/max_mid_band1.csv') # should fail because the buffer is too small\n",
    "\n",
    "# Grab the newest hpso csv file from Git\n",
    "##############################\n",
    "# app.read_hpso_csv(csv_file=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine computational capacity required for realtime processing\n",
    "\n",
    "SDP needs to be able to change the observation at arbitrary times, so enough computational resources need to be reserved to deal with the most expensive case. This is determined based on parameters already calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.computational_capacity()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate graph\n",
    "\n",
    "Generates a shuffled sequence with all HPSOs appearing roughly as often as expected in a real-life schedule then a graph of tasks is created. The node info can be displayed by setting `display_node_info` to True.\n",
    "\n",
    "Note that in contrast to Francois' scheduler, the resource usage of every task is fixed up-front, so certain key sizes are set here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20 days of observation\n",
    "Tsequence = 20 * 24 * 3600\n",
    "# Each observation must be at least 10 minutes\n",
    "Tobs_min = 10 * 60\n",
    "# Number of jobs to run in parallel\n",
    "batch_parallelism = 2\n",
    "display_node_info = False\n",
    "\n",
    "app.generate_graph(Tsequence, Tobs_min, batch_parallelism, display_node_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity-check\n",
    "\n",
    "Checking there's enough capacity to run every task in isolation and resources aren't over-used on average, in order to keep up with observations. \n",
    "\n",
    "This is a rough estimate of safety that also under-estimates the cost of edges in high-pressure scenarios. For example, if something needs to be kept in the buffer for longer, it has a higher footprint than estimated here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.sanity_check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schedule tasks\n",
    "\n",
    "A task time is assigned to every node, then resource usages and edge lengths are calculated along the way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.schedule_tasks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efficiency calculations\n",
    "\n",
    "Interactively choose capacities to see how the overall efficiency is affected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.efficiency_calculations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate failures\n",
    "\n",
    "Creates a temporary capacity change then re-schedules twice (once the capacity reduces, and once it's restored) to simulate failures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.failures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SDP HPSO Scheduling\n",
    "\n",
    "Last run with Jupyter Notebook 5.0.0 running Python 3.5.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "sys.path += ['..']\n",
    "from sdp_par_model import reports as iapi\n",
    "from sdp_par_model.parameters.definitions import *\n",
    "from sdp_par_model.parameters.definitions import Constants as c\n",
    "\n",
    "from sdp_par_model.scheduler import Definitions as sdefs\n",
    "from sdp_par_model.scheduler import Scheduler\n",
    "\n",
    "import collections\n",
    "import warnings\n",
    "import bisect\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = 16, 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Scheduler object\n",
    "At the moment the Scheduler object contains the functionality of the SDP Simulator, the scheduler, as well as the generated schedule. In future we may wish to split them into separate classes and objects "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sdp_scheduler = Scheduler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read  performace requirement lookup for all HPSOs. \n",
    "### If this lookup table does not exist, we create it, and save it to disk (to save time re-computing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "performance_lookup_filename = \"performance_dict.data\"\n",
    "if os.path.isfile(performance_lookup_filename):\n",
    "    performance_dict = None\n",
    "    with open(performance_lookup_filename, \"rb\") as f:\n",
    "        performance_dict = pickle.load(f)\n",
    "    sdp_scheduler.set_performance_dictionary(performance_dict)\n",
    "else:\n",
    "    # Create a performance dictionary and write it to file\n",
    "    performance_dict = sdp_scheduler.compute_performance_dictionary()\n",
    "    with open(performance_lookup_filename, \"wb\") as f:\n",
    "        pickle.dump(performance_dict, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's create run a short test sequence\n",
    "### This can be modified so that the list is read from e.g. a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seqL = ('A','A','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','A','A','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','A','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B')\n",
    "seqM = ('B','G','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','G','C','F','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','G','G','E','E','E','E','D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' To show how the tasks are created, we convert a test sequence to Task objects.\n",
    " (The two A's at the start isn't a mistake -- it shows how a repeat of the same task type leads to unique \n",
    " subtask IDs being created '''\n",
    "\n",
    "test_seq = ('A','A','B','C','E','F','G')\n",
    "test_seq = ('A',)\n",
    "\n",
    "sdp_scheduler.task_letters_to_sdp_task_list(test_seq)\n",
    "for task in sdp_scheduler.task_list:\n",
    "    print(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdp_scheduler.schedule(sdp_flops=22.8, assign_flops_fraction=0.3, assign_bandwidth_fraction=0.8, max_nr_iterations=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "iapi.plot_deltas(sdp_scheduler.flops_deltas, 'Evolution of SDP FLOP/s', 'wall clock time (hours)', 'PetaFLOP/s')\n",
    "iapi.plot_deltas(sdp_scheduler.memory_deltas, 'Evolution of SDP working memory (RAM)', 'wall clock time (hours)', 'TeraByte')\n",
    "iapi.plot_deltas(sdp_scheduler.cold_buffer_deltas, 'Evolution of SDP Cold buffer', 'wall clock time (hours)', 'TeraByte')\n",
    "iapi.plot_deltas(sdp_scheduler.hot_buffer_deltas, 'Evolution of SDP Hot buffer', 'wall clock time (hours)', 'TeraByte')\n",
    "iapi.plot_deltas(sdp_scheduler.preserve_deltas, 'Evolution of SDP Preservation storage', 'wall clock time (hours)', 'TeraByte')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The blocks below this line are legacy (test) code.\n",
    "## It will probably not be able to run due to changes to the code since they were written. For reference use only! (advice: only execute if you think that know what you're doing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate the execution of this sequence on the SDP and plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sequence_to_simulate = seqL\n",
    "\n",
    "task_list = sdp_scheduler.task_letters_to_sdp_task_list(sequence_to_simulate)\n",
    "\n",
    "schedule = Scheduler.schedule(task_list, sdp_FLOPS, max_nr_iterations=1000, assign_sdp_fraction=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hard-coded performace costs and requirements from Rosie's Excel sheet\n",
    "### These were previously used in rev [3372fdd] to approximately replicate Rosie's results. Check (rerun) the notebook at that repository revision to regenerate those results - not repeated here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The following sets of values should be computed using the parametric model. Just hard-coded for now (from Excel)\n",
    "hpso_ingest_rates = {'A':0.459, 'B':3e-3, 'C':0.117, 'D':0.112, 'E':0.0603, 'F':0.244, 'G':0.438}  # in TeraByte/s\n",
    "# FLOPcounts below are the PetaFLOPs required to process one second of ingested data\n",
    "hpso_flopcounts = {'A':50.4, 'B':2.0, 'C':7.5, 'D':6.2, 'E':2.9833, 'F':17.689, 'G':27.698}  # in PetaFLOP/s\n",
    "hpso_durations  = {'A':6, 'B':0.17, 'C':6, 'D':6, 'E':4.4, 'F':0.1233, 'G':6}  # in hours -- TODO check whether correct\n",
    "\n",
    "sdp_setup_time = 60  # the minimum amount of time between processing tasks on the SDP (seconds)\n",
    "telecope_setup_time = 0  # TODO is this correct?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproduction of \"Low\" and \"Mid\" sequences from Rosie's Excel sheet\n",
    "### Create a lists of observation tasks as letter sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seqL = ('A','A','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','A','A','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','A','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B')\n",
    "seqM = ('B','G','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','G','C','F','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','G','G','E','E','E','E','D')\n",
    "\n",
    "print('HPSO LOW task distribution (number of occurences) A..B = (%.0f, %.0f)' % (seqL.count('A'), seqL.count('B')))\n",
    "tA = seqL.count('A') * hpso_durations['A']\n",
    "tB = seqL.count('B') * hpso_durations['B']\n",
    "print('HPSO LOW task distribution (observation time) A..B = (%.1f%%, %.1f%%)' % (100 * tA / (tA + tB), 100 * tB / (tA + tB)))\n",
    "\n",
    "tA = seqM.count('A')\n",
    "tB = seqM.count('B')\n",
    "tC = seqM.count('C')\n",
    "tD = seqM.count('D')\n",
    "tE = seqM.count('E')\n",
    "tF = seqM.count('F')\n",
    "tG = seqM.count('G')\n",
    "tt = len(seqM)\n",
    "\n",
    "print('\\nHPSO MID task distribution (number of occurences) A..G = (%.0f, %.0f, %.0f, %.0f, %.0f, %.0f, %.0f)' % \\\n",
    "      (tA, tB, tC, tD, tE, tF, tG))\n",
    "print('HPSO MID task distribution (observation time) A..G = (%.1f%%, %.1f%%, %.1f%%, %.1f%%, %.1f%%, %.1f%%, %.1f%%)' % \\\n",
    "      (100*tA/tt, 100*tB/tt, 100*tC/tt, 100*tD/tt, 100*tE/tt, 100*tF/tt, 100*tG/tt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

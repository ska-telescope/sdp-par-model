{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SDP HPSO Scheduling\n",
    "\n",
    "Last run with Jupyter Notebook 5.0.0 running Python 3.5.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path += ['..']\n",
    "from sdp_par_model import reports as iapi\n",
    "from sdp_par_model.config import PipelineConfig\n",
    "from sdp_par_model.parameters.definitions import *\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import collections\n",
    "import warnings\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 16, 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: the HPSO lookup refers to only one part of the HPSO pipeline, and that definion is in itself duplicated \n",
    "# in definitions.py. Needs some refactoring methinks\n",
    "hpso_lookup = {'A':HPSOs.hpso01ICAL, 'B':HPSOs.hpso04c, 'C':HPSOs.hpso13ICAL, 'D':HPSOs.hpso14ICAL, \n",
    "               'E':HPSOs.hpso15ICAL, 'F':HPSOs.hpso27ICAL, 'G':HPSOs.hpso37cICAL}\n",
    "\n",
    "# The following sets of values should be computed using the parametric model. Just hard-coded for now (from Excel)\n",
    "hpso_ingest_rates = {'A':0.459, 'B':3e-3, 'C':0.117, 'D':0.112, 'E':0.0603, 'F':0.244, 'G':0.438}  # in TeraByte/s\n",
    "# FLOPcounts below are the PetaFLOPs required to process one second of ingested data\n",
    "hpso_flopcounts = {'A':50.4, 'B':2.0, 'C':7.5, 'D':6.2, 'E':2.9833, 'F':17.689, 'G':27.698}  # in PetaFLOP/s\n",
    "hpso_durations  = {'A':6, 'B':0.17, 'C':6, 'D':6, 'E':4.4, 'F':0.1233, 'G':6}  # in hours -- TODO check whether correct\n",
    "\n",
    "sdp_setup_time = 60  # the minimum amount of time between processing tasks on the SDP (seconds)\n",
    "telecope_setup_time = 0  # TODO is this correct?\n",
    "\n",
    "seqL = ('A','A','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','A','A','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','A','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B')\n",
    "seqM = ('B','G','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','G','C','F','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','G','G','E','E','E','E','D')\n",
    "\n",
    "acc = 0\n",
    "search_char = 'A'\n",
    "for c in seqL:\n",
    "    if c == search_char:\n",
    "        acc += 1\n",
    "\n",
    "hpso_distribution_count = {'A' : acc / len(seqL), 'B' : 1 - acc / len(seqL)}\n",
    "    \n",
    "print('HPSO Low division (number) A:B = %.0f : %.0f' % (hpso_distribution_count['A'] * len(seqL), hpso_distribution_count['B']  * len(seqL)))\n",
    "tA = hpso_distribution_count['A'] * hpso_durations['A']\n",
    "tB = hpso_distribution_count['B'] * hpso_durations['B']\n",
    "print('HPSO Low division (time)   A:B = %.1f%% : %.1f%%' % (100 * tA / (tA + tB), 100 * tB / (tA + tB)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First simple reproduction of Rosie's \"Low\" sequence\n",
    "### First, create a list of observation task objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Observation:\n",
    "    uid          = None  # Optional: unique ID; can be used for sequencing\n",
    "    t_obs        = None  # duration of the observation\n",
    "    t_obs_start  = None  # Wall clock time that this observation starts (in seconds)\n",
    "    t_proc_start = None  # Wall clock time that this observation's processing starts (in seconds)\n",
    "    t_proc_end   = None  # Wall clock time that this observation's processing ends (in seconds)    \n",
    "    bufsize      = None  # Amount of memory (in TB) that this operation needs to store in the buffer    \n",
    "    flopcount    = None  # Number of floating point operations required to finish this observation\n",
    "\n",
    "def add_delta(deltas, t, delta):\n",
    "    if t in deltas:\n",
    "        warnings.warn('Timestamp entry already exists in the timeline')\n",
    "        deltas[t] += delta\n",
    "    else:\n",
    "        deltas[t] = delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Virutally execute the task list for LOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = []\n",
    "uid =  0\n",
    "for task in seqL:\n",
    "    o = Observation()\n",
    "    o.uid = uid\n",
    "    uid += 1\n",
    "    p = ParameterContainer()\n",
    "    apply_hpso_parameters(p, hpso_lookup[task])\n",
    "    o.t_obs = p.Tobs\n",
    "    o.bufsize = p.Tobs * hpso_ingest_rates[task]\n",
    "    o.flopcount = hpso_flopcounts[task]\n",
    "    tasks.append(o)\n",
    "\n",
    "sdp_FLOPS = 22.8  # NB: The processing capacity of the SDP in PetaFLOP/s\n",
    "\n",
    "# Run through the list of tasks, determining start and end times for their execution and the effect on the buffer\n",
    "\n",
    "wall_clock = 0       # Simulated wall clock time (seconds)\n",
    "buffer_deltas = {}   # a dictionary mapping wall clock times to buffer allocation / deallocation (+/-) sizes\n",
    "t_proc_end_last = 0  # The wall clock time that the last process completed\n",
    "idle_time_durations = np.zeros(len(tasks))  # in seconds\n",
    "i = 0\n",
    "\n",
    "for task in tasks:\n",
    "    task.t_obs_start = wall_clock\n",
    "    add_delta(buffer_deltas, task.t_obs_start, task.bufsize)\n",
    "    t_obs_end = task.t_obs_start + task.t_obs  # Time the observation completes\n",
    "    task.t_proc_start = max(t_obs_end, t_proc_end_last + sdp_setup_time)\n",
    "    task.t_proc_end   = task.t_proc_start + task.flopcount * task.t_obs / sdp_FLOPS\n",
    "    add_delta(buffer_deltas, task.t_proc_end, -task.bufsize)\n",
    "    t_proc_end_last = task.t_proc_end\n",
    "    wall_clock = t_obs_end + telecope_setup_time\n",
    "    idle_time_durations[i] = task.t_proc_start - t_obs_end\n",
    "    i += 1\n",
    "\n",
    "buffer_evolution = collections.OrderedDict(sorted(buffer_deltas.items()))\n",
    "time_vals   = np.zeros(2 * len(buffer_evolution))\n",
    "buffer_vals = np.zeros(2 * len(buffer_evolution))\n",
    "\n",
    "i = 0\n",
    "buffer_val = 0\n",
    "time_val   = 0\n",
    "for k, delta in buffer_evolution.items(): \n",
    "    #print('(%.1f,\\t%.2f)' % (k/3600, delta))\n",
    "    time_val = k / 3600  # hours\n",
    "    time_vals[i]     = time_val\n",
    "    buffer_vals[i]   = buffer_val\n",
    "    buffer_val += delta  # Adds the buffer delta to the buffer's stored contents\n",
    "    time_vals[i+1]   = time_val  # we assume no time went by (writing being instantaneous)\n",
    "    buffer_vals[i+1] = buffer_val  # TeraBytes\n",
    "    i += 2\n",
    "\n",
    "plt.plot(time_vals, buffer_vals / 1e3, 'b-')\n",
    "plt.title('Evolution of the SDP Buffer while executing the supplied LOW sequence.\\nObservation time = %.1f hrs.' \n",
    "          ' Total execution time = %.1f hrs; Max buffer = %.1f PB' % (wall_clock / 3600, time_vals[-1],                                                                      np.max(buffer_vals)/1e3))\n",
    "plt.xlabel('time (hours)')\n",
    "plt.ylabel('buffer usage (PB)')\n",
    "plt.xlim(0, time_vals[-1])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.array(range(len(idle_time_durations))), idle_time_durations / 3600, marker='s', color = 'r', linewidth=0)\n",
    "plt.title('Idle time that tasks spend in the LOW buffer.\\nSummed idle time for all tasks = %.1f hrs.' % \n",
    "          (np.sum(idle_time_durations) / 3600))\n",
    "plt.xlabel('Task''s number in sequence')\n",
    "plt.ylabel('Time (hours)')\n",
    "\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat execution for MID's task list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = []\n",
    "uid =  0\n",
    "for task in seqM:\n",
    "    o = Observation()\n",
    "    o.uid = uid\n",
    "    uid += 1\n",
    "    p = ParameterContainer()\n",
    "    apply_hpso_parameters(p, hpso_lookup[task])\n",
    "    o.t_obs = p.Tobs\n",
    "    o.bufsize = p.Tobs * hpso_ingest_rates[task]\n",
    "    o.flopcount = hpso_flopcounts[task]\n",
    "    tasks.append(o)\n",
    "\n",
    "sdp_FLOPS = 22.8  # NB: The processing capacity of the SDP in PetaFLOP/s\n",
    "\n",
    "# Run through the list of tasks, determining start and end times for their execution and the effect on the buffer\n",
    "\n",
    "wall_clock = 0       # Simulated wall clock time (seconds)\n",
    "buffer_deltas = {}   # a dictionary mapping wall clock times to buffer allocation / deallocation (+/-) sizes\n",
    "t_proc_end_last = 0  # The wall clock time that the last process completed\n",
    "idle_time_durations = np.zeros(len(tasks))  # in seconds\n",
    "i = 0\n",
    "\n",
    "for task in tasks:\n",
    "    task.t_obs_start = wall_clock\n",
    "    add_delta(buffer_deltas, task.t_obs_start, task.bufsize)\n",
    "    t_obs_end = task.t_obs_start + task.t_obs  # Time the observation completes\n",
    "    task.t_proc_start = max(t_obs_end, t_proc_end_last + sdp_setup_time)\n",
    "    task.t_proc_end   = task.t_proc_start + task.flopcount * task.t_obs / sdp_FLOPS\n",
    "    add_delta(buffer_deltas, task.t_proc_end, -task.bufsize)\n",
    "    t_proc_end_last = task.t_proc_end\n",
    "    wall_clock = t_obs_end + telecope_setup_time\n",
    "    idle_time_durations[i] = task.t_proc_start - t_obs_end\n",
    "    i += 1\n",
    "\n",
    "buffer_evolution = collections.OrderedDict(sorted(buffer_deltas.items()))\n",
    "time_vals   = np.zeros(2 * len(buffer_evolution))\n",
    "buffer_vals = np.zeros(2 * len(buffer_evolution))\n",
    "\n",
    "i = 0\n",
    "buffer_val = 0\n",
    "time_val   = 0\n",
    "for k, delta in buffer_evolution.items(): \n",
    "    #print('(%.1f,\\t%.2f)' % (k/3600, delta))\n",
    "    time_val = k / 3600  # hours\n",
    "    time_vals[i]     = time_val\n",
    "    buffer_vals[i]   = buffer_val\n",
    "    buffer_val += delta  # Adds the buffer delta to the buffer's stored contents\n",
    "    time_vals[i+1]   = time_val  # we assume no time went by (writing being instantaneous)\n",
    "    buffer_vals[i+1] = buffer_val  # TeraBytes\n",
    "    i += 2\n",
    "\n",
    "plt.plot(time_vals, buffer_vals / 1e3, 'b-')\n",
    "plt.title('Evolution of the SDP Buffer while executing the supplied MID sequence.\\nObservation time = %.1f hrs.' \n",
    "          ' Total execution time = %.1f hrs; Max buffer = %.1f PB' % (wall_clock / 3600, time_vals[-1],                                                                      np.max(buffer_vals)/1e3))\n",
    "plt.xlabel('time (hours)')\n",
    "plt.ylabel('buffer usage (PB)')\n",
    "plt.xlim(0, time_vals[-1])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.array(range(len(idle_time_durations))), idle_time_durations / 3600, 'r*')\n",
    "plt.title('Idle time that tasks spend in the MID buffer.\\nSummed idle time for all tasks = %.1f hrs.' % \n",
    "          (np.sum(idle_time_durations) / 3600))\n",
    "plt.xlabel('Task''s number in sequence')\n",
    "plt.ylabel('Time (hours)')\n",
    "\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratchpad\n",
    "## Example code taken from computing parametric model results by Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for pipeline in Pipelines.all:\n",
    "    iapi.stack_bars_pipelines(\"%s Computational Requirements [PetaFLOP/s]\" % pipeline, teles, bands, [pipeline],\n",
    "                              parallel=parallel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for band in bands:\n",
    "    iapi.stack_bars_pipelines(\"%s Computational Requirements [PetaFLOP/s]\" % band, teles, [band], Pipelines.all,\n",
    "                              parallel = parallel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "iapi.stack_bars_hpsos(\"HPSOs Computational Requirements [PetaFLOP/s]\", HPSOs.hpsos,\n",
    "                      parallel=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

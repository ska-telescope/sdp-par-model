{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SDP HPSO Scheduling\n",
    "\n",
    "Last run with Jupyter Notebook 5.0.0 running Python 3.5.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "sys.path += ['..']\n",
    "from sdp_par_model import reports as iapi\n",
    "from sdp_par_model.parameters.definitions import *\n",
    "from sdp_par_model.parameters.definitions import Constants as c\n",
    "\n",
    "from sdp_par_model.scheduler import Definitions as sdefs\n",
    "from sdp_par_model.scheduler import Scheduler\n",
    "\n",
    "import collections\n",
    "import warnings\n",
    "import bisect\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = 16, 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computes  performace requirements for each HPSO using parametric model\n",
    "We do this once, and store the results in a dictionary (and to a file object) for future lookup without re-computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "performance_lookup_filename = \"performance_dict.data\"\n",
    "\n",
    "performance_dict = None\n",
    "if os.path.isfile(performance_lookup_filename):\n",
    "    with open(performance_lookup_filename, \"rb\") as f:\n",
    "        performance_dict = pickle.load(f)\n",
    "else:\n",
    "    # Create a performance dictionary and write it to file\n",
    "    performance_dict = Scheduler.compute_performance_lookup_table()\n",
    "    with open(performance_lookup_filename, \"wb\") as f:\n",
    "        pickle.dump(performance_dict, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's create run a short test sequence\n",
    "### This can be modified so that the list is read from e.g. a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seqL = ('A','A','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','A','A','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','A','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B')\n",
    "seqM = ('B','G','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','G','C','F','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','G','G','E','E','E','E','D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' To show how the tasks are created, we convert a test sequence to Task objects.\n",
    " (The two A's at the start isn't a mistake -- it shows how a repeat of the same task type leads to unique \n",
    " subtask IDs being created '''\n",
    "\n",
    "test_seq = ('A','A','B','C','E','F','G')\n",
    "\n",
    "task_list = Scheduler.task_letters_to_SDPTask_list(test_seq, performance_dict)\n",
    "for task in task_list:\n",
    "    print(task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate the execution of this sequence on the SDP and plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_to_simulate = seqL\n",
    "sdp_FLOPS = 22.8  # NB: The processing capacity of the SDP in PetaFLOP/s\n",
    "task_list = Scheduler.task_letters_to_SDPTask_list(sequence_to_simulate, performance_dict)\n",
    "\n",
    "schedule = Scheduler.schedule(task_list, sdp_FLOPS, max_nr_iterations=1000, assign_sdp_fraction=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iapi.plot_deltas(schedule.flops_deltas, 'Evolution of SDP FLOP/s', 'wall clock time (hours)', 'PetaFLOP/s')\n",
    "iapi.plot_deltas(schedule.memory_deltas, 'Evolution of SDP working memory (RAM)', 'wall clock time (hours)', 'TeraByte')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iapi.plot_deltas(schedule.flops_deltas, 'Evolution of SDP FLOP/s', 'wall clock time (hours)', 'PetaFLOP/s')\n",
    "iapi.plot_deltas(schedule.memory_deltas, 'Evolution of SDP working memory (RAM)', 'wall clock time (hours)', 'TeraByte')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The blocks below this line are legacy (test) code.\n",
    "## It will probably not be able to run due to changes to the code since they were written. For reference use only! (advice: only execute if you think that know what you're doing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hard-coded performace costs and requirements from Rosie's Excel sheet\n",
    "### These were previously used in rev [3372fdd] to approximately replicate Rosie's results. Check (rerun) the notebook at that repository revision to regenerate those results - not repeated here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The following sets of values should be computed using the parametric model. Just hard-coded for now (from Excel)\n",
    "hpso_ingest_rates = {'A':0.459, 'B':3e-3, 'C':0.117, 'D':0.112, 'E':0.0603, 'F':0.244, 'G':0.438}  # in TeraByte/s\n",
    "# FLOPcounts below are the PetaFLOPs required to process one second of ingested data\n",
    "hpso_flopcounts = {'A':50.4, 'B':2.0, 'C':7.5, 'D':6.2, 'E':2.9833, 'F':17.689, 'G':27.698}  # in PetaFLOP/s\n",
    "hpso_durations  = {'A':6, 'B':0.17, 'C':6, 'D':6, 'E':4.4, 'F':0.1233, 'G':6}  # in hours -- TODO check whether correct\n",
    "\n",
    "sdp_setup_time = 60  # the minimum amount of time between processing tasks on the SDP (seconds)\n",
    "telecope_setup_time = 0  # TODO is this correct?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproduction of \"Low\" and \"Mid\" sequences from Rosie's Excel sheet\n",
    "### Create a lists of observation tasks as letter sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seqL = ('A','A','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','A','A','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','A','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B')\n",
    "seqM = ('B','G','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','G','C','F','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','B','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','F','G','G','E','E','E','E','D')\n",
    "\n",
    "print('HPSO LOW task distribution (number of occurences) A..B = (%.0f, %.0f)' % (seqL.count('A'), seqL.count('B')))\n",
    "tA = seqL.count('A') * hpso_durations['A']\n",
    "tB = seqL.count('B') * hpso_durations['B']\n",
    "print('HPSO LOW task distribution (observation time) A..B = (%.1f%%, %.1f%%)' % (100 * tA / (tA + tB), 100 * tB / (tA + tB)))\n",
    "\n",
    "tA = seqM.count('A')\n",
    "tB = seqM.count('B')\n",
    "tC = seqM.count('C')\n",
    "tD = seqM.count('D')\n",
    "tE = seqM.count('E')\n",
    "tF = seqM.count('F')\n",
    "tG = seqM.count('G')\n",
    "tt = len(seqM)\n",
    "\n",
    "print('\\nHPSO MID task distribution (number of occurences) A..G = (%.0f, %.0f, %.0f, %.0f, %.0f, %.0f, %.0f)' % \\\n",
    "      (tA, tB, tC, tD, tE, tF, tG))\n",
    "print('HPSO MID task distribution (observation time) A..G = (%.1f%%, %.1f%%, %.1f%%, %.1f%%, %.1f%%, %.1f%%, %.1f%%)' % \\\n",
    "      (100*tA/tt, 100*tB/tt, 100*tC/tt, 100*tD/tt, 100*tE/tt, 100*tF/tt, 100*tG/tt))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scheduling (2019 refactoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "\n",
    "from matplotlib import pylab\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "from sdp_par_model import reports, config\n",
    "from sdp_par_model.scheduling import graph, level_trace\n",
    "from sdp_par_model.parameters import definitions\n",
    "from sdp_par_model.parameters.definitions import Telescopes, Pipelines, Constants, HPSOs\n",
    "from sdp_par_model import config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set observatory parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telescope_flops = {\n",
    "    Telescopes.SKA1_Low: int(13.8 * Constants.peta),\n",
    "    Telescopes.SKA1_Mid: int(12.1 * Constants.peta),\n",
    "}\n",
    "buffer_size = {\n",
    "    Telescopes.SKA1_Low: int(46.0 * Constants.peta),\n",
    "    Telescopes.SKA1_Mid: int(39.0 * Constants.peta),\n",
    "}\n",
    "hot_buffer_size = {\n",
    "    Telescopes.SKA1_Low: int(buffer_size[Telescopes.SKA1_Low] / 2.7),\n",
    "    Telescopes.SKA1_Mid: int(buffer_size[Telescopes.SKA1_Mid] / 2.7)\n",
    "}\n",
    "delivery_buffer_size = {\n",
    "    Telescopes.SKA1_Low: int(buffer_size[Telescopes.SKA1_Low] / 30),\n",
    "    Telescopes.SKA1_Mid: int(buffer_size[Telescopes.SKA1_Mid] / 30)\n",
    "}\n",
    "input_buffer_size = {\n",
    "    tel : buffer_size[tel] - hot_buffer_size[tel] - delivery_buffer_size[tel] for tel in buffer_size\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read HPSO performance characteristics\n",
    "\n",
    "As generated by the export notebook. This always picks up the latest file checked into Git."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = reports.read_csv(reports.newest_csv(reports.find_csvs()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine computational capacity required for realtime processing\n",
    "\n",
    "As SKA SDP needs to be able to change observation at arbitrary times, we need to always reserve enough computational resources to deal with the most expensive case. Here we figure this out automatically based on the calculated parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpsos = definitions.HPSOs.all_hpsos\n",
    "realtime_flops = { tel: 0 for tel in definitions.Telescopes.available_teles }\n",
    "realtime_flops_hpso = {}\n",
    "for hpso in definitions.HPSOs.all_hpsos:\n",
    "    # Sum FLOP rates over involved real-time pipelines\n",
    "    rt_flops = 0\n",
    "    for pipeline in definitions.HPSOs.hpso_pipelines[hpso]:\n",
    "        cfg_name = config.PipelineConfig(hpso=hpso, pipeline=pipeline).describe()\n",
    "        flops = int(math.ceil(float(reports.lookup_csv(csv, cfg_name, 'Total Compute Requirement')) * definitions.Constants.peta))\n",
    "        if pipeline in definitions.Pipelines.realtime:\n",
    "            rt_flops += flops\n",
    "    # Dominates?\n",
    "    telescope = definitions.HPSOs.hpso_telescopes[hpso]\n",
    "    if rt_flops > realtime_flops[telescope]:\n",
    "        realtime_flops[telescope] = rt_flops\n",
    "        realtime_flops_hpso[telescope] = hpso\n",
    "        \n",
    "# Show\n",
    "print(\"Realtime processing requirements:\")\n",
    "batch_flops = { tel : tel_flops - realtime_flops[tel] for tel, tel_flops in telescope_flops.items() }\n",
    "for tel in definitions.Telescopes.available_teles:\n",
    "    print(\" {}: {:.3f} Pflop/s real-time (from {}), {:.3f} Pflop/s left for batch\".format(\n",
    "        tel, realtime_flops[tel] / definitions.Constants.peta,\n",
    "        realtime_flops_hpso[tel], batch_flops[tel] / definitions.Constants.peta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate graph\n",
    "\n",
    "Generate a sequence with all HPSOs appearing roughly as often as we expect them in a real-life schedule. We then shuffle this list and generate a (multi-)graph of tasks from it.\n",
    "\n",
    "Note that in contrast to Francois' scheduler, the resource usage of every task is fixed up-front, therefore we need to declare certain key sizes here. Adjust as necessary in relation to the capacities (see below) to get the desired amount of parallelism between tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tsequence = 10 * 24 * 3600 # 10 days\n",
    "telescope = Telescopes.SKA1_Low\n",
    "Tobs_min = 0 # 10 min\n",
    "\n",
    "cold_transfer_rate = 0.5 * definitions.Constants.tera # Bytes/s\n",
    "offline_flop_rate = batch_flops[telescope]\n",
    "hot_buffer_rate = 9.5 * definitions.Constants.tera # Byte/s\n",
    "delivery_rate = 100 / 8 * definitions.Constants.giga # Bytes/s\n",
    "if telescope == Telescopes.SKA1_Mid:\n",
    "    delivery_rate *= 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Texp = {}; Tobs = {}; Rflop = {}\n",
    "for hpso in HPSOs.all_hpsos:\n",
    "    if HPSOs.hpso_telescopes[hpso] == telescope:\n",
    "        tp = config.PipelineConfig(hpso=hpso, pipeline=Pipelines.Ingest).calc_tel_params()\n",
    "        Texp[hpso] = tp.Texp; Tobs[hpso] = max(tp.Tobs, Tobs_min)\n",
    "\n",
    "Texp_total = sum(Texp.values())\n",
    "hpso_sequence = []\n",
    "Rflop_sum = 0; Tobs_sum = 0\n",
    "for hpso in HPSOs.all_hpsos:\n",
    "    if HPSOs.hpso_telescopes[hpso] == telescope:\n",
    "        count = int(math.ceil(Tsequence * Texp[hpso] / Tobs[hpso] / Texp_total))\n",
    "        print(\"{} x {} (Tobs={:.1f}h, Texp={:.1f}h)\".format(count, hpso, Tobs[hpso]/3600, Texp[hpso]/3600))\n",
    "        hpso_sequence.extend(count * [hpso])\n",
    "        Tobs_sum += count * Tobs[hpso]\n",
    "print(\"{:.3f} d total\".format(Tobs_sum / 3600 / 24))\n",
    "random.shuffle(hpso_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = []\n",
    "t = time.time()\n",
    "for hpso in hpso_sequence:\n",
    "    hnodes = graph.make_graph(csv, {'hpso': hpso},\n",
    "                              cold_transfer_rate, offline_flop_rate, hot_buffer_rate, delivery_rate)\n",
    "    nodes.extend(hnodes)\n",
    "print(\"Multi-graph has {} nodes (generation took {:.3f}s)\".format(len(nodes), time.time()-t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Capacities\n",
    "\n",
    "These are the limits scheduling is going to assume for every cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capacities = {\n",
    "    graph.Resources.Observatory: 1,\n",
    "    graph.Resources.BatchCompute: batch_flops[telescope], # Flops/s\n",
    "    graph.Resources.RealtimeCompute: realtime_flops[telescope], # Flops/s\n",
    "    graph.Resources.InputBuffer: input_buffer_size[telescope], # Byte\n",
    "    graph.Resources.HotBuffer: hot_buffer_size[telescope], # Byte\n",
    "    graph.Resources.OutputBuffer: delivery_buffer_size[telescope], # Byte\n",
    "    graph.Resources.IngestRate: int(0.7 * definitions.Constants.tera), # Byte/s\n",
    "    graph.Resources.ColdBufferRate: int(2 * 0.7 * definitions.Constants.tera), # Byte/s\n",
    "    graph.Resources.HotBufferRate: int(5.0 * definitions.Constants.tera), # Byte/s\n",
    "    graph.Resources.DeliveryRate: int(100/8 * definitions.Constants.giga),  # Byte/s\n",
    "    graph.Resources.LTSRate: int(100/8 * definitions.Constants.giga), # Byte/s\n",
    "}\n",
    "# HACK: Adjustments to make things work\n",
    "if telescope == Telescopes.SKA1_Mid:\n",
    "    capacities[graph.Resources.OutputBuffer] *= 3\n",
    "    capacities[graph.Resources.DeliveryRate] *= 6\n",
    "capacities[graph.Resources.HotBufferRate] *= 2\n",
    "units = {\n",
    "    graph.Resources.BatchCompute: (\"PFLOP/s\", Constants.peta),\n",
    "    graph.Resources.RealtimeCompute: (\"PFLOP/s\", Constants.peta),\n",
    "    graph.Resources.InputBuffer: (\"PB\", Constants.peta),\n",
    "    graph.Resources.HotBuffer: (\"PB\", Constants.peta),\n",
    "    graph.Resources.OutputBuffer: (\"PB\", Constants.peta),\n",
    "    graph.Resources.IngestRate: (\"TB/s\", Constants.tera),\n",
    "    graph.Resources.ColdBufferRate: (\"TB/s\", Constants.tera),\n",
    "    graph.Resources.HotBufferRate: (\"TB/s\", Constants.tera),\n",
    "    graph.Resources.DeliveryRate: (\"TB/s\", Constants.tera),\n",
    "    graph.Resources.LTSRate: (\"TB/s\", Constants.tera),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity-check Capacities\n",
    "\n",
    "We can do a number of consistency checks at this point: Clearly we should have enough capacity to run every task in isolation.\n",
    "\n",
    "Furthermore, in order to keep up with observations we need to make sure that we are not over-using any resource on average. This is a pretty rough estimate of safety that especially under-estimates the cost of edges in high-pressure scenarios. For example, if somethings needs to be kept in the buffer for longer, it has a higher footprint than estimated here. Therefore especially the size of `input-buffer` and `output-buffer` should be quite generous here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "cost_sum = { cost : 0 for cost in capacities.keys() }\n",
    "for task in nodes:\n",
    "    for cost, amount in task.all_cost().items():\n",
    "        assert cost in capacities, \"No {} capacity defined, required by {}!\".format(cost, task.name)\n",
    "        assert amount <= capacities[cost], \"Not enough {} capacity to run {} ({:g}<{:g}!)\".format(\n",
    "            cost, task.name, capacities[cost], amount)\n",
    "        # Try to compute an average. Edges are the main wild-card here: We only know that they stay\n",
    "        # around at least for the lifetime of the dependency *and* the longest dependent task.\n",
    "        ttime = task.time\n",
    "        if cost in task.edge_cost and len(task.rev_deps) > 0:\n",
    "            ttime += max([d.time for d in task.rev_deps])\n",
    "        cost_sum[cost] += ttime * amount\n",
    "print(\"Best-case average loads:\")\n",
    "for cost in graph.Resources.All:\n",
    "    unit, mult = units[cost]\n",
    "    avg = cost_sum[cost] / Tobs_sum\n",
    "    cap = capacities[cost]\n",
    "    print(\" {}:\\t{:.3f} {} ({:.1f}% of {:.3f} {})\".format(cost, avg/mult, unit, avg/cap*100, cap/mult, unit))\n",
    "    # Warn past 75%\n",
    "    if avg > cap:\n",
    "        print('Likely insufficient {} capacity!'.format(cost), file=sys.stderr,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schedule tasks\n",
    "\n",
    "Assign a task time to every node, and figure out resource usages and edge lengths along the way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sdp_par_model.scheduling import scheduler\n",
    "\n",
    "t = time.time()\n",
    "usage, task_time, task_edge_end_time = scheduler.schedule(nodes, capacities, verbose=False)\n",
    "print(\"Scheduling took {:.3f}s\".format(time.time() - t))\n",
    "print(\"Observing efficiency: {:.1f}%\".format(Tobs_sum / usage[graph.Resources.Observatory].end() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trace_end = max(*task_edge_end_time.values())\n",
    "pylab.figure(figsize=(16,40))\n",
    "for n, cost in enumerate(graph.Resources.All):\n",
    "    levels = usage[cost]\n",
    "    avg = levels.average(0,trace_end)    \n",
    "    unit, mult = units[cost]\n",
    "    pylab.subplot(len(usage), 1, n+1)\n",
    "    pylab.step([0] + [ t/24/3600 for t in levels._trace.keys() ] + [trace_end],\n",
    "               [0] + [ v/mult for v in  levels._trace.values() ] + [0],\n",
    "               where='post')\n",
    "    pylab.title(\"{}: {:.3f} {} average ({:.2f}%)\".format(\n",
    "        cost, avg/mult, unit, avg / capacities[cost] * 100))\n",
    "    pylab.xlim((0, trace_end/24/3600)); pylab.xticks(range(int(trace_end)//24//3600+1))\n",
    "    pylab.ylim((0, capacities[cost] / mult * 1.01))\n",
    "    pylab.ylabel(unit)\n",
    "pylab.xlabel(\"Days\")\n",
    "pylab.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

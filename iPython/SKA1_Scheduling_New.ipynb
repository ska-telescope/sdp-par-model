{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scheduling (2019 refactoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "from ipywidgets import interact_manual, SelectMultiple\n",
    "from matplotlib import pylab\n",
    "\n",
    "sys.path.insert(0, \"..\")\n",
    "from sdp_par_model import reports, config\n",
    "from sdp_par_model.scheduling import graph, level_trace, scheduler\n",
    "from sdp_par_model.parameters import definitions\n",
    "from sdp_par_model.parameters.definitions import Telescopes, Pipelines, Constants, HPSOs\n",
    "from sdp_par_model import config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall observatory selection & capacities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telescope = Telescopes.SKA1_Mid\n",
    "\n",
    "# Telescope-specific system sizing\n",
    "if telescope == Telescopes.SKA1_Low:\n",
    "    total_flops = int(13.8 * Constants.peta) # FLOP/s\n",
    "    buffer_size = int(46.0 * Constants.peta) # Byte\n",
    "    hot_buffer_size = int(buffer_size / 2.7) # Byte\n",
    "else:\n",
    "    total_flops = int(12.1 * Constants.peta) # FLOP/s\n",
    "    buffer_size = int(46.0 * Constants.peta) # Byte\n",
    "    hot_buffer_size = int(buffer_size / 2.4) # Byte\n",
    "\n",
    "# Common system sizing\n",
    "ingest_rate = 0.45 * Constants.tera # Byte/s\n",
    "cold_rate = ingest_rate + 0.65 * Constants.tera # Byte/s\n",
    "hot_rate = 5.0 * Constants.tera # Byte/s\n",
    "delivery_rate = int(100/8 * Constants.giga)  # Byte/s\n",
    "lts_rate = delivery_rate\n",
    "\n",
    "# Extra allowance for delivery\n",
    "delivery_buffer_size = int(buffer_size / 30) # Byte\n",
    "input_buffer_size = buffer_size - hot_buffer_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read HPSO performance characteristics\n",
    "\n",
    "Loads high performance science objective characteristics generated by the export notebook. This always picks up the latest file checked into Git."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = reports.read_csv(reports.newest_csv(reports.find_csvs()))\n",
    "csv = reports.strip_csv(csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine computational capacity required for realtime processing\n",
    "\n",
    "As SKA SDP needs to be able to change observation at arbitrary times, we need to always reserve enough computational resources to deal with the most expensive case. Here we figure this out automatically based on the calculated parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "realtime_flops = 0\n",
    "realtime_flops_hpso = None\n",
    "for hpso in definitions.HPSOs.all_hpsos:\n",
    "    if definitions.HPSOs.hpso_telescopes[hpso] != telescope:\n",
    "        continue\n",
    "    # Sum FLOP rates over involved real-time pipelines\n",
    "    rt_flops = 0\n",
    "    for pipeline in definitions.HPSOs.hpso_pipelines[hpso]:\n",
    "        cfg_name = config.PipelineConfig(hpso=hpso, pipeline=pipeline).describe()\n",
    "        flops = int(math.ceil(float(reports.lookup_csv(csv, cfg_name, 'Total Compute Requirement')) * definitions.Constants.peta))\n",
    "        if pipeline in definitions.Pipelines.realtime:\n",
    "            rt_flops += flops\n",
    "    # Dominates?\n",
    "    if rt_flops > realtime_flops:\n",
    "        realtime_flops = rt_flops\n",
    "        realtime_flops_hpso = hpso\n",
    "        \n",
    "# Show\n",
    "print(\"Realtime processing requirements:\")\n",
    "batch_flops = total_flops - realtime_flops\n",
    "print(\" {:.3f} Pflop/s real-time (from {}), {:.3f} Pflop/s left for batch\".format(\n",
    "    realtime_flops / definitions.Constants.peta,\n",
    "    realtime_flops_hpso, batch_flops / definitions.Constants.peta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derive capacities\n",
    "\n",
    "Now that we know the split between batch and realtime processing, we can formulate the capacity dictionary that will be used in scheduling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capacities = {\n",
    "    graph.Resources.Observatory: 1,\n",
    "    graph.Resources.BatchCompute: batch_flops,\n",
    "    graph.Resources.RealtimeCompute: realtime_flops,\n",
    "    graph.Resources.InputBuffer: input_buffer_size,\n",
    "    graph.Resources.HotBuffer: hot_buffer_size,\n",
    "    graph.Resources.OutputBuffer: delivery_buffer_size,\n",
    "    graph.Resources.IngestRate: ingest_rate,\n",
    "    graph.Resources.ColdBufferRate: cold_rate,\n",
    "    graph.Resources.HotBufferRate: hot_rate,\n",
    "    graph.Resources.DeliveryRate: delivery_rate,\n",
    "    graph.Resources.LTSRate: lts_rate\n",
    "}\n",
    "\n",
    "# HACKs: Adjustments to make things work\n",
    "if telescope == Telescopes.SKA1_Mid:\n",
    "    capacities[graph.Resources.OutputBuffer] *= 3\n",
    "    capacities[graph.Resources.DeliveryRate] *= 6\n",
    "capacities[graph.Resources.HotBufferRate] *= 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate graph\n",
    "\n",
    "Generate a sequence with all HPSOs appearing roughly as often as we expect them in a real-life schedule. We then shuffle this list and generate a (multi-)graph of tasks from it.\n",
    "\n",
    "Note that in contrast to Francois' scheduler, the resource usage of every task is fixed up-front, therefore we need to declare certain key sizes here. Adjust as necessary in relation to the capacities (see below) to get the desired amount of parallelism between tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tsequence = 20 * 24 * 3600\n",
    "Tobs_min = 10 * 60\n",
    "\n",
    "hpso_sequence, Tobs_sum = graph.make_hpso_sequence(telescope, Tsequence, Tobs_min, verbose=True)\n",
    "print(\"{:.3f} d total\".format(Tobs_sum / 3600 / 24))\n",
    "random.shuffle(hpso_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "nodes = graph.hpso_sequence_to_nodes(csv, hpso_sequence, capacities, Tobs_min)\n",
    "print(\"Multi-graph has {} nodes (generation took {:.3f}s)\".format(len(nodes), time.time()-t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity-check Graph\n",
    "\n",
    "We can do a number of consistency checks at this point: Clearly we should have enough capacity to run every task in isolation.\n",
    "\n",
    "Furthermore, in order to keep up with observations we need to make sure that we are not over-using any resource on average. This is a pretty rough estimate of safety that especially under-estimates the cost of edges in high-pressure scenarios. For example, if somethings needs to be kept in the buffer for longer, it has a higher footprint than estimated here. Therefore especially the size of `input-buffer` and `output-buffer` should be quite generous here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "cost_sum = { cost : 0 for cost in capacities.keys() }\n",
    "for task in nodes:\n",
    "    for cost, amount in task.all_cost().items():\n",
    "        assert cost in capacities, \"No {} capacity defined, required by {}!\".format(cost, task.name)\n",
    "        assert amount <= capacities[cost], \"Not enough {} capacity to run {} ({:g}<{:g}!)\".format(\n",
    "            cost, task.name, capacities[cost], amount)\n",
    "        # Try to compute an average. Edges are the main wild-card here: We only know that they stay\n",
    "        # around at least for the lifetime of the dependency *and* the longest dependent task.\n",
    "        ttime = task.time\n",
    "        if cost in task.edge_cost and len(task.rev_deps) > 0:\n",
    "            ttime += max([d.time for d in task.rev_deps])\n",
    "        cost_sum[cost] += ttime * amount\n",
    "print(\"Best-case average loads:\")\n",
    "for cost in graph.Resources.All:\n",
    "    unit, mult = graph.Resources.units[cost]\n",
    "    avg = cost_sum[cost] / Tobs_sum\n",
    "    cap = capacities[cost]\n",
    "    print(\" {}:\\t{:.3f} {} ({:.1f}% of {:.3f} {})\".format(cost, avg/mult, unit, avg/cap*100, cap/mult, unit))\n",
    "    # Warn past 75%\n",
    "    if avg > cap:\n",
    "        print('Likely insufficient {} capacity!'.format(cost), file=sys.stderr,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schedule tasks\n",
    "\n",
    "Assign a task time to every node, and figure out resource usages and edge lengths along the way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "usage, task_time, task_edge_end_time = scheduler.schedule(nodes, capacities, verbose=False)\n",
    "print(\"Scheduling took {:.3f}s\".format(time.time() - t))\n",
    "print(\"Observing efficiency: {:.1f}%\".format(Tobs_sum / usage[graph.Resources.Observatory].end() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trace_end = max(*task_edge_end_time.values())\n",
    "pylab.figure(figsize=(16,40))\n",
    "for n, cost in enumerate(graph.Resources.All):\n",
    "    levels = usage[cost]\n",
    "    avg = levels.average(0,trace_end)    \n",
    "    unit, mult = graph.Resources.units[cost]\n",
    "    pylab.subplot(len(usage), 1, n+1)\n",
    "    pylab.step([0] + [ t/24/3600 for t in levels._trace.keys() ] + [trace_end],\n",
    "               [0] + [ v/mult for v in  levels._trace.values() ] + [0],\n",
    "               where='post')\n",
    "    pylab.title(\"{}: {:.3f} {} average ({:.2f}%)\".format(\n",
    "        cost, avg/mult, unit, avg / capacities[cost] * 100))\n",
    "    pylab.xlim((0, trace_end/24/3600)); pylab.xticks(range(int(trace_end)//24//3600+1))\n",
    "    pylab.ylim((0, capacities[cost] / mult * 1.01))\n",
    "    pylab.ylabel(unit)\n",
    "pylab.xlabel(\"Days\")\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efficiency calculations\n",
    "\n",
    "We can play around with capacities and see how it affects overall efficiency. This takes quite a bit, so let's set up some multiprocessing infrastructure to take advantage of parallelism:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_efficiencies(cost_amounts):\n",
    "    cost, amounts = cost_amounts\n",
    "    # Make new HPSO sequence\n",
    "    hpso_seq = list(hpso_sequence)\n",
    "    random.shuffle(hpso_seq)\n",
    "    # Schedule, collect efficiencies\n",
    "    effs = []\n",
    "    for a in amounts:\n",
    "        cap = dict(capacities)\n",
    "        cap[cost] = int(a)\n",
    "        nodes = graph.hpso_sequence_to_nodes(csv, hpso_seq, cap, Tobs_min)\n",
    "        try:\n",
    "            usage, task_time, task_edge_end_time = scheduler.schedule(nodes, cap, verbose=False)\n",
    "            effs.append(Tobs_sum / usage[graph.Resources.Observatory].end() * 100)\n",
    "        except ValueError:\n",
    "            effs.append(None)\n",
    "    return effs\n",
    "# Set up multiprocessing map. Fall back to standard map if the system doesn't support it (e.g. Windows)\n",
    "try:\n",
    "    import multiprocessing\n",
    "    mp_pool = multiprocessing.Pool(multiprocessing.cpu_count() // 2)\n",
    "    mp_map = mp_pool.map\n",
    "except:\n",
    "    print(\"Falling back to single-threaded map. This should work, but is very slow!\", file=sys.stderr)\n",
    "    mp_map = map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import matplotlib.lines\n",
    "\n",
    "interesting_costs = [ cost for cost in graph.Resources.All\n",
    "                      if cost not in [graph.Resources.RealtimeCompute,\n",
    "                                      graph.Resources.IngestRate,\n",
    "                                      graph.Resources.LTSRate ]]\n",
    "@interact_manual(costs=SelectMultiple(options=graph.Resources.All, value=interesting_costs),\n",
    "                 percent=(1,100,1), steps=(1,10,1), count=(1,100,1))\n",
    "def test_sensitivity(costs=graph.Resources.All, percent=20, steps=5, count=12):\n",
    "    graph_count = len(costs)\n",
    "    pylab.figure(figsize=(8,graph_count*4))\n",
    "    pylab.subplots_adjust(hspace=0.4)\n",
    "    for graph_ix, cost in enumerate(costs):\n",
    "        # Calculate efficiencies for different amounts\n",
    "        amounts = capacities[cost] * (1+numpy.arange(-percent, percent+steps, steps)/100)\n",
    "        effs = numpy.transpose(list(mp_map(determine_efficiencies, count * [(cost, amounts)])))\n",
    "        # Filter out \"None\" values\n",
    "        sel = numpy.all(effs != None, axis=1)\n",
    "        amounts = amounts[sel]; effs = effs[sel]\n",
    "        # Draw percentiles\n",
    "        unit,mult = graph.Resources.units[cost]\n",
    "        percents = [10,25,50,75,90]; styles = [':', '--', '-', '--', ':']\n",
    "        percentiles = numpy.percentile(effs, percents, axis=1)\n",
    "        pylab.subplot(graph_count, 1, graph_ix+1)\n",
    "        for p, eff_ps, style in zip(percents, percentiles, styles):\n",
    "            pylab.plot(amounts/mult, eff_ps, label=\"{}%\".format(p), linestyle=style, color='blue')\n",
    "        # Draw line for \"default\" value\n",
    "        ymin, ymax = pylab.gca().get_ybound()\n",
    "        if ymin < 80:\n",
    "            ymin = 80; pylab.gca().set_ylim((80, ymax))\n",
    "        pylab.gca().add_line(matplotlib.lines.Line2D([capacities[cost]/mult,capacities[cost]/mult], [ymin,ymax],\n",
    "                                                     color='black', linestyle=':'))\n",
    "        # Titles\n",
    "        pylab.title('{} sensitivity'.format(cost)); pylab.xlabel(\"[{}]\".format(unit))\n",
    "        pylab.ylabel(\"Efficiency [%]\")\n",
    "        pylab.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
